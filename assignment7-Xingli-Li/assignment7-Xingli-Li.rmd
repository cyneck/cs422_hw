---
title: "CS 422 Homework 7"
author: "Xingli Li"
output:
  html_notebook: 
    toc: yes
    toc_float: yes
    toc_depth: 5
  html_document:
    toc: yes
    df_print: paged
---

## Homework 7

### Part 2

set work space and install dependent package.

```{r}
# install.packages("keras")
library(keras)
library(dplyr)
library(caret)
setwd("/media/eric/Data/IIT/CS422/cs422_hw/assignment7-Xingli-Li")
```

### 2.1-(a)

Loading origin data and processing data.

```{r}
df <- read.csv("activity-small.csv")

set.seed(1122)
df <- df[sample(nrow(df)), ] # Shuffle, as all of the data in the .csv file
                             # is ordered by label!  This will cause problems
                             # if we do not shuffle as the validation split
                             # may not include observations of class 3 (the
                             # class that occurs at the end).  The validation_
                             # split parameter samples from the end of the
                             # training set.


indx <- sample(1:nrow(df), 0.20*nrow(df))
test.df  <- df[indx, ]
train.df <- df[-indx, ]

label.test <- test.df$label
test.df$label <- NULL
test.df <- as.data.frame(scale(test.df))
test.df$label <- label.test
rm(label.test)

label.train <- train.df$label
train.df$label <- NULL
train.df <- as.data.frame(scale(train.df))
train.df$label <- label.train
rm(label.train)
rm(indx)

```

```{r}
use_condaenv("base")

create_model <- function (){
  model <- keras_model_sequential()  # input layer
  layer_flatten(model,input_shape = c(3) )
  layer_dense(model,units = 128, activation = 'relu')     # hidden layer
  layer_dense(model, units = 4, activation = 'softmax')   # output layer

  compile(model,
          optimizer = optimizer_adam(),
          loss = 'categorical_crossentropy',
          metrics = 'accuracy')
  model
}

model <- create_model()
summary(model)

```

training

```{r}

train_X <- as.matrix(train.df[,1:3])
train_y <- to_categorical(train.df$label,4, dtype = "int32")

history <- model %>% fit(train_X,
                         train_y,
                         epochs = 100,
                         batch_size = 1,
                         validation_split = 0.2)
plot(history)
```

evaluate model

```{r}
options(digits = 3)
test_X <- as.matrix(test.df[,1:3])
test_y <- to_categorical(test.df$label,4, dtype = "int32")
model %>% evaluate(test_X, test_y)
```

confusing matrix

```{r}
pred <- model %>% predict(test_X)
pred_res <-  apply(pred,1,which.max)-1
test_res <-  test.df$label
table(pred_res,test_res)

```

### 2.1-(a)-(i)

What is the overall accuracy of your model on the test dataset?

Answer:
      The overall accuracy of the model: 0.815

### 2.1-(a)-(ii)

What is the per-class sensitivity, specificity, and balanced accuracy on the test dataset?

```{r}

get_metrics <- function (pred_res,test_res){

  xtable <- confusionMatrix(table(pred_res,test_res))

  # Extract acc, bal.acc, error, spec, sens, and prec from the variable a.
  acc <- xtable$overall["Accuracy"]
  bal.acc <- xtable$byClass[,"Balanced Accuracy"]
  spec <- xtable$byClass[,"Specificity"]
  sens <- xtable$byClass[,"Sensitivity"]
  prec <- xtable$byClass[,"Precision"]

  results.df <- data.frame(sens = sens,
                           spec = spec,
                           bal.acc = bal.acc,
                           prec = prec)

  print("Batch gradient descent")
  print(paste0("Overall accuarcy:",acc))

  class_range <- c(0,1,2,3)

  for (i in class_range){
    class <- paste0("Class: ",i)
    print(paste(class,
                ": Sens. =",round(results.df$sens[i+1], 3),
                ", Spec. =",round(results.df$spec[i+1],3),
                ", Bal.Acc. =",round(results.df$bal.acc[i+1],3)
    ))
  }

  c(acc,results.df)
}

metrics <- get_metrics(pred_res,test_res)

```


### 2.1-(b)

```{r}

print_metrics2 <- function (batch_size, time, pred_res, test_res){

  xtable <- confusionMatrix(table(pred_res,test_res))

  acc <- xtable$overall["Accuracy"]
  bal.acc <- xtable$byClass[,"Balanced Accuracy"]
  spec <- xtable$byClass[,"Specificity"]
  sens <- xtable$byClass[,"Sensitivity"]
  prec <- xtable$byClass[,"Precision"]

  results.df <- data.frame(sens = sens,
                           spec = spec,
                           bal.acc = bal.acc,
                           prec = prec)

  print(paste("Batch size:",batch_size))
  print(paste0("Time taken to train neural network: ",round(time,3)," (seconds)"))
  print(paste0("Overall accuarcy: ",acc))

  class_range <- c(0,1,2,3)
  for (i in class_range){
    class <- paste0("Class: ",i)

    print(paste(class,
                ": Sens. =",round(results.df$sens[i+1], 3),
                ", Spec. =",round(results.df$spec[i+1],3),
                ", Bal.Acc. =",round(results.df$bal.acc[i+1],3)
    ))
  }
  print("")

  c(acc,results.df)
}


options(digits = 3)

batch_size_range <- c(1,32,64,128,256)

for (batch_size in batch_size_range){
  begin <- Sys.time()

  model <- NULL
  model <- create_model()

  history <- model %>% fit(train_X,
                           train_y,
                           epochs = 100,
                           batch_size = batch_size,
                           validation_split = 0.2)
  end <- Sys.time()
  time <- difftime(end, begin, units="secs")

  pred <- model %>% predict(test_X)
  pred_res <-  apply(pred,1,which.max)-1

  print_metrics2(batch_size, time, pred_res, test_res)

}


```

### 2.1-(c)-(i)

Analyze the output from the mini-batch gradient descent. Why do you think that the time vary as you increase the batch size?

Answer:

     Time decreases as batch size increase. Because stochastic gradient descent is continuous, batch size is the number of samples
selected for a training, using a larger batch size allows computer to parallelize the computation more, at the same time, the size of the batch size
affects convergence speed of the model.

### 2.1-(c)-(ii)

Comment on the output from the mini-batch gradient descent. Does overall accuracy, balanced accuracy and per-class statistics remain the same? Change? If change, why?

Answer:

     These metrics is all changed almost, but they remain stable level.
     When the network is trained, one mini-batch samples is input into the network at one time, and then their gradient is calculated for back propagation.
Because one mini-batch samples is used in calculating the gradient, the calculated gradient direction is more accurate. In this case, the gradient value is very different.

### 2.1-(d)

Add one hidden layer, re-train, observing.
```{r}

create_model2 <- function (){
  model2 <- keras_model_sequential()  # input layer
  layer_flatten(model2,input_shape = c(3) )
  layer_dense(model2,units = 128, activation = 'relu')  # hidden layer
  layer_dense(model2,units = 64, activation = 'relu')  # hidden layer
  layer_dense(model2, units = 4, activation = 'softmax')     # output layer

  compile(model2,
          optimizer = optimizer_adam(),
          loss = 'categorical_crossentropy',
          metrics = 'accuracy')
  model2
}

model2 <- create_model2()
summary(model2)

# trainning
history2 <- model2 %>% fit(train_X,
                         train_y,
                         epochs = 100,
                         batch_size = 128,
                         validation_split = 0.2)

plot(history2)

```


### 2.1-(d)-(i)

Overall accuracy of your model on the test dataset.

```{r}
# predicting
pred2 <- model2 %>% predict(test_X)
pred2_res <-  apply(pred2,1,which.max)-1

# confuse matrix
xtable <- confusionMatrix(table(pred2_res,test_res))
acc <- xtable$overall["Accuracy"]

print("Overall accuracy of your model on the test dataset:")
acc
```

### 2.1-(d)-(ii)

Per-class sensitivity, specificity, and balanced accuracy on the test dataset. Pick the construction that had the best performance results and compare that to the performance you observed in (a). Comment on the changes you observed by adding a new hidden layer. (Does the performance increase? Decrease? Stay the same?)

```{r}
main_metrics <- xtable$byClass[,c("Balanced Accuracy","Specificity","Sensitivity")]
main_metrics
```

Answer:
      The performance stay the same.