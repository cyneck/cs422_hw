---
title: "CS 422 Homework 7"
author: "Xingli Li"
output:
  html_notebook: 
    toc: yes
    toc_float: yes
    toc_depth: 5
  html_document:
    toc: yes
    df_print: paged
---

## Homework 7

### Part 2

set work space and install dependent package.

```{r}
# devtools::install_github("rstudio/keras")
library(keras)
library(dplyr)
library(caret)
setwd("/media/eric/Data/IIT/CS422/cs422_hw/assignment7-Xingli-Li")
```

### 2.1-(a)

Loading origin data and processing data.

```{r}
df <- read.csv("activity-small.csv")

set.seed(1122)
df <- df[sample(nrow(df)), ] # Shuffle, as all of the data in the .csv file
                             # is ordered by label!  This will cause problems
                             # if we do not shuffle as the validation split
                             # may not include observations of class 3 (the
                             # class that occurs at the end).  The validation_
                             # split parameter samples from the end of the
                             # training set.


indx <- sample(1:nrow(df), 0.20*nrow(df))
test.df  <- df[indx, ]
train.df <- df[-indx, ]

label.test <- test.df$label
test.df$label <- NULL
test.df <- as.data.frame(scale(test.df))
test.df$label <- label.test
rm(label.test)

label.train <- train.df$label
train.df$label <- NULL
train.df <- as.data.frame(scale(train.df))
train.df$label <- label.train
rm(label.train)
rm(indx)

```

```{r}
model <- keras_model_sequential()  # input layer
layer_flatten(model,input_shape = 3 )
layer_dense(model,units = 128, activation = 'relu')  # hidden layer # dropout
layer_dense(model, units = 4, activation = 'softmax')     # output layer

compile(model,
  optimizer = 'adam',
  loss = 'sparse_categorical_crossentropy',
  metrics = 'accuracy')

summary(model)

```

training

```{r}
train.X <- train.df[,1:3]
train.y <- train.df$label

history <-  fit(model,train.X,train.y,
                         epochs = 10,
                         batch_size = 1,
                         validation_split = 0.2)
plot(history)
```

evaluate model

```{r}
test.X <- test.df[,1:3]
test.y <- test.df$label
model %>% evaluate(test.X, test.y)
```

confusing matrix

```{r}
pred <- model %>% predict(test.X)
pred_res <-  apply(pred,1,which.max)-1
test_res <-  test.y
table(test_res,pred_res)

```

### 2.1-(a)-(i)

What is the overall accuracy of your model on the test dataset?

### 2.1-(a)-(ii)

What is the per-class sensitivity, specificity, and balanced accuracy on the test dataset?

### 2.1-(b)

### 2.1-(c)-(i)

Analyze the output from the mini-batch gradient descent. Why do you think that the time vary as you increase the batch size?

### 2.1-(c)-(ii)

Comment on the output from the mini-batch gradient descent. Does overall accuracy, balanced accuracy and per-class statistics remain the same? Change? If change, why?

### 2.1-(d)-(i)

Overall accuracy of your model on the test dataset.

### 2.1-(d)-(ii)

Per-class sensitivity, specificity, and balanced accuracy on the test dataset. Pick the construction that had the best performance results and compare that to the performance you observed in (a). Comment on the changes you observed by adding a new hidden layer. (Does the performance increase? Decrease? Stay the same?)
